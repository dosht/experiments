{
 "metadata": {
  "name": "SGD + Text Hashing Vectorizing"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Trial on yahoo directory - simple first\n",
      "# load\n",
      "from sklearn.datasets import fetch_mldata\n",
      "yahoo_directory = fetch_mldata(\"yahoo-web-directory-topics\")  # fetch from the Interne. It's gonna take some time at first call\n",
      "X = yahoo_directory.data\n",
      "y = yahoo_directory.target\n",
      "classes = np.unique(y)\n",
      "\n",
      "# preparing train set and test set\n",
      "split = y.shape[0] * 7 / 10\n",
      "X_train = X[:split, :]\n",
      "y_train = y[:split]\n",
      "X_validation = X[split:, :]\n",
      "y_validation = y[split:]\n",
      "\n",
      "# train\n",
      "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
      "clf1 = SGDClassifier()\n",
      "clf1.fit(X_train, y_train)\n",
      "clf1.score(X_validation, y_validation)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "0.60542168674698793"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now using partial fit\n",
      "from scipy.sparse import lil_matrix\n",
      "n_of_features = X.shape[1]\n",
      "data_train = zip(X_train, y_train)\n",
      "def parallelize(data, n): return [data[s*len(data)/n:e*len(data)/n] for (s, e) in zip(range(0, n), range(1, n+1))]\n",
      "parts = parallelize(data_train, 10)\n",
      "clf2 = SGDClassifier()\n",
      "for part in parts:\n",
      "    y = np.zeros(len(part))\n",
      "    X = lil_matrix((len(part), n_of_features), dtype=float64)\n",
      "    for i, sample in enumerate(part):\n",
      "        xi, yi = sample\n",
      "        X[i, :n_of_features] = xi\n",
      "        y[i] = yi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "# TODO: start from here load the andrew ng docs and start playing\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now parallized over spark\n",
      "from pyspark import SparkContext\n",
      "sc = SparkContext(\"local\", \"SGD-text\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    }
   ],
   "metadata": {}
  }
 ]
}